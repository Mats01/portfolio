# Is AI here now?

## The Uncertainty Problem

Here's the uncomfortable truth: we do not know how this AI thing is going to play out. The companies building these tools have every incentive to make us believe AI is revolutionary, but is that really the case.

What I find notable is that the actual data tells a different story than the headlines. Outside of tech, we are not seeing significant job displacement (at least not yet). No surge in layoffs. No rising unemployment. AI hasn't been the disruptor that was feared / promised.

This is, of course, a great thing to hear; people aren't losing their jobs. There is however a cynical way to look at this: if AI could genuinely perform tasks without human guidance, we'd be seeing economic displacement. We're not. That's a hard-numbers way of saying these tools might not be as useful as advertised.

Tech layoffs are a separate phenomenon; more about investment corrections than AI replacement. But outside the tech sphere, the job market seems largely unaffected (more thoughts on possible explanations for this coming later).

Consider this a checkpoint. In 2026, AI is genuinely useful for coding. As I'll explain, it's transformed my workflow, but it apparently hasn't delivered the same value elsewhere.


## Brilliant and Stupid Simultaneously

Some people dismiss AI as "just autocomplete" that is "just predicting the next word". They're grosely underestimating what's at stake. At my company, one person now does what previously required three. We've entirely stopped looking for interns. I don't know how an intern would fit into our workflow anymore. A year ago, I expected we'd bring someone on to help me. Instead, I got that help—from a model in the cloud.

One thing is certain; AI is really hard to estimate. When AI solves a task brilliantly, I instinctively assign it human-like intelligence. Only a smart person could have done this, I think. But that's not what's actually happening. The AI can excel at one task and fail completely at a closely related one, even within the same domain. This breaks our mental model of intelligence. With humans, there's consistency, someone who struggles in one area usually struggles in related areas. AI doesn't work that way. You can't extrapolate from one success to predict another.

Understanding this is crucial for anyone using these tools. You have to manage expectations. You have to manage costs, because these models aren't free, and deploying them based on false assumptions—as many non-tech companies are discovering—can be financially ruinous.


## Engineers are still needed, but for how long?

Plot this out assuming even linear improvement, and it's not hard to imagine non-technical people shipping medium-complexity apps by prompting their way through the gotchas and edge cases.

Developers today are already far more productive than developers writing assembly or early C thanks to modern frameworks and languages. But those people were always programmers—passionate about understanding how things worked at whatever level of abstraction they operated on.

Now we're moving away from that, fast.

For the short term—even a few years out—engineers are still necessary, and I'm comfortable with my position. 
I'm more productive than ever, shipping more and cleaner code, more nimble in how I work. 
And I definitely still feel like a software engineer, even when I type prompts in plain english and marvel at the code that has just appeared out of thin electrons in many many graphics cards somewhere. 

The question is, how long will I still be needed? Could someone else do this without me? After watching a non-technical person attempt it: no. I'm still necessary, but will this ever change?
Looking further ahead, the landscape becomes impossible to predict. Many jobs seem vulnerable.

On a recent episode of [Connected](https://www.relay.fm/connected/587) Myke and Federico discussed just this. What particularely made me think what the comparison of AI tools to Excel for accountants or Squarespace for web development.

Excel didn't eliminate accountants, it made them more productive. We still need accountants because the domain knowledge matters. Maybe there are fewer of them now, or maybe accounting just got more complex to match their new capabilities. Squarespace lets non-developers build websites, just as AI lets non-programmers build apps. But developers still exist. There are just more websites now. People still hire professionals because they don't want to learn Squarespace, or because complex work exceeds its capabilities. There are even "Squarespace builders" - people you hire to set up your Squarespace site.

Are these jobs disappearing, or just changing? Maybe these tools will change the work rather than eliminating it.


## Why AI Hasn't Disrupted Other Industries

So why hasn't AI replaced jobs outside software engineering?

I think it comes down to how programmers are different than other people. In job interviews for developement positions, you prove your knowledge. In many other fields, you show past experience and demonstrate you're pleasant to work with. Developers need deep competence. We're accustomed to constant learning, rapid adaptation, obsessive efficiency. If I were a clerk or a salesperson, I'd probably be faster with AI assistance. But that's not happening at scale.

Part of the problem might be that managers try to make AI an employee rather than an augmentation, or it's just that workers in other fields aren't conditioned to think about productivity the way developers are. They're not looking for ways to be more efficient, their jobs may not even reward efficiency.

Here's what crystallizes everything for me. When I'm coding and solving real problems, I'm constantly impressed by how smart the AI seems. But maybe I'm the smart one, and the AI is just very good at following precise directions.

Could AI run a small business autonomously? Based on [everything I've seen](https://www.youtube.com/watch?v=SpPhm7S9vsQ): no.

This becomes obvious when I try using AI for non-coding tasks. "Make me a marketing plan" yields vague platitudes: maybe post on social media, maybe make a landing page. It can't produce a realistic, grounded plan with specific actions and timelines.

But when I'm coding with precise instructions? It impresses me every time.

The difference is that I know how to be precise in my domain. I have the vocabulary, the file references, the pattern knowledge, the awareness of edge cases. I can give the AI exactly the context it needs to succeed.

Other professions lack this infrastructure of precision. Their work isn't structured for unambiguous direction-giving. And perhaps their jobs don't reward, or even recognize, the kind of productivity gains AI could theoretically provide.


